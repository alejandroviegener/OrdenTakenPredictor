{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('.venv')",
   "display_name": "Python 3.8.5 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "d99e53e6ba37c9ce744e72f2c4f6b34e9b9cb96ba6ffda5d56a657fde0263a32"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Random forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import pipeline\n",
    "from sklearn import compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "base_dir = \"../datasets/\"\n",
    "orders_df = pd.read_csv(base_dir + \"orders.csv\")\n",
    "\n",
    "# Convert timestamp to date time\n",
    "orders_df[\"created_at\"] = pd.to_datetime(orders_df[\"created_at\"])\n",
    "\n",
    "# Create date related features\n",
    "# Year and month are left out, see\n",
    "orders_df[\"day_of_week\"] = orders_df[\"created_at\"].dt.dayofweek\n",
    "orders_df[\"month\"] = orders_df[\"created_at\"].dt.month\n",
    "orders_df[\"time_of_day\"] = orders_df[\"created_at\"].dt.hour + orders_df[\"created_at\"].dt.minute / 60\n",
    "orders_df[\"day_of_month\"] = orders_df[\"created_at\"].dt.day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter outliers\n",
    "\n",
    "filter_elevation = (orders_df[\"to_user_elevation\"] < 600) \n",
    "filter_earnings = (orders_df[\"total_earning\"] < 40000) & (orders_df[\"total_earning\"] > 0)\n",
    "filter_distance = orders_df[\"to_user_distance\"] < 8\n",
    "\n",
    "orders_df = orders_df[filter_elevation & filter_earnings & filter_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['order_id', 'store_id', 'to_user_distance', 'to_user_elevation',\n",
       "       'total_earning', 'created_at', 'taken', 'day_of_week', 'month',\n",
       "       'time_of_day', 'day_of_month'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "orders_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = orders_df[[\"to_user_distance\", \"to_user_elevation\", \"total_earning\", \"day_of_week\", \"time_of_day\", \"day_of_month\"]]\n",
    "labels = orders_df[\"taken\"]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(features, labels, test_size = 0.25, stratify=labels, random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['to_user_distance', 'to_user_elevation', 'total_earning', 'day_of_week',\n",
       "       'time_of_day', 'day_of_month'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Verify selected features\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    36744.000000\n",
       "mean         0.921212\n",
       "std          0.269412\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "Name: taken, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Verify strtification\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=20,\n",
       "                       max_leaf_nodes=100, min_samples_split=1000)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# First model using weight balancing\n",
    "model = ensemble.RandomForestClassifier(n_estimators=100, min_samples_split=1000, max_depth=20, class_weight=\"balanced\", max_leaf_nodes=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ROC-auc train 0.6830791785622553\n",
      "ROC-auc train 0.6600150439539699\n"
     ]
    }
   ],
   "source": [
    "# Get scores\n",
    "print( \"ROC-auc train\", metrics.roc_auc_score(y_train, model.predict(X_train)))\n",
    "print( \"ROC-auc test\", metrics.roc_auc_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='x', ylabel='y'>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"263.513624pt\" version=\"1.1\" viewBox=\"0 0 385.78125 263.513624\" width=\"385.78125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-10-21T19:41:53.964564</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 263.513624 \nL 385.78125 263.513624 \nL 385.78125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 225.957374 \nL 378.58125 225.957374 \nL 378.58125 8.517374 \nL 43.78125 8.517374 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PolyCollection_1\">\n    <defs>\n     <path d=\"M 127.988034 -47.439886 \nL 126.974466 -47.439886 \nL 126.389532 -49.407798 \nL 125.357604 -51.375709 \nL 123.741993 -53.34362 \nL 121.500694 -55.311532 \nL 118.74825 -57.279443 \nL 115.752601 -59.247354 \nL 112.842097 -61.215265 \nL 110.259529 -63.183177 \nL 108.048645 -65.151088 \nL 106.0464 -67.118999 \nL 103.985116 -69.086911 \nL 101.638837 -71.054822 \nL 98.930561 -73.022733 \nL 95.953955 -74.990644 \nL 92.915998 -76.958556 \nL 90.040385 -78.926467 \nL 87.477643 -80.894378 \nL 85.256097 -82.86229 \nL 83.287227 -84.830201 \nL 81.416396 -86.798112 \nL 79.492976 -88.766024 \nL 77.430093 -90.733935 \nL 75.233487 -92.701846 \nL 72.993599 -94.669757 \nL 70.846855 -96.637669 \nL 68.920434 -98.60558 \nL 67.282028 -100.573491 \nL 65.918796 -102.541403 \nL 64.758546 -104.509314 \nL 63.720922 -106.477225 \nL 62.765468 -108.445136 \nL 61.90785 -110.413048 \nL 61.203137 -112.380959 \nL 60.719103 -114.34887 \nL 60.52125 -116.316782 \nL 60.670634 -118.284693 \nL 61.219734 -120.252604 \nL 62.194856 -122.220516 \nL 63.569625 -124.188427 \nL 65.247278 -126.156338 \nL 67.069273 -128.124249 \nL 68.854171 -130.092161 \nL 70.452718 -132.060072 \nL 71.794073 -134.027983 \nL 72.901301 -135.995895 \nL 73.8701 -137.963806 \nL 74.824016 -139.931717 \nL 75.870171 -141.899628 \nL 77.074512 -143.86754 \nL 78.458744 -145.835451 \nL 80.007178 -147.803362 \nL 81.673048 -149.771274 \nL 83.386319 -151.739185 \nL 85.071467 -153.707096 \nL 86.674366 -155.675007 \nL 88.18265 -157.642919 \nL 89.622773 -159.61083 \nL 91.033729 -161.578741 \nL 92.436051 -163.546653 \nL 93.817177 -165.514564 \nL 95.139908 -167.482475 \nL 96.364244 -169.450387 \nL 97.467453 -171.418298 \nL 98.453215 -173.386209 \nL 99.349733 -175.35412 \nL 100.201095 -177.322032 \nL 101.055325 -179.289943 \nL 101.950848 -181.257854 \nL 102.9045 -183.225766 \nL 103.907106 -185.193677 \nL 104.931618 -187.161588 \nL 105.951689 -189.129499 \nL 106.960508 -191.097411 \nL 107.978162 -193.065322 \nL 109.042746 -195.033233 \nL 110.190508 -197.001145 \nL 111.43646 -198.969056 \nL 112.76581 -200.936967 \nL 114.139944 -202.904879 \nL 115.512346 -204.87279 \nL 116.844862 -206.840701 \nL 118.115912 -208.808612 \nL 119.318631 -210.776524 \nL 120.453233 -212.744435 \nL 121.519784 -214.712346 \nL 122.514849 -216.680258 \nL 123.431622 -218.648169 \nL 124.261423 -220.61608 \nL 124.995146 -222.583991 \nL 125.624769 -224.551903 \nL 126.145428 -226.519814 \nL 126.557729 -228.487725 \nL 126.869043 -230.455637 \nL 127.092778 -232.423548 \nL 127.245836 -234.391459 \nL 127.345525 -236.359371 \nL 127.407232 -238.327282 \nL 127.443352 -240.295193 \nL 127.463182 -242.263104 \nL 127.499318 -242.263104 \nL 127.499318 -242.263104 \nL 127.519148 -240.295193 \nL 127.555268 -238.327282 \nL 127.616975 -236.359371 \nL 127.716664 -234.391459 \nL 127.869722 -232.423548 \nL 128.093457 -230.455637 \nL 128.404771 -228.487725 \nL 128.817072 -226.519814 \nL 129.337731 -224.551903 \nL 129.967354 -222.583991 \nL 130.701077 -220.61608 \nL 131.530878 -218.648169 \nL 132.447651 -216.680258 \nL 133.442716 -214.712346 \nL 134.509267 -212.744435 \nL 135.643869 -210.776524 \nL 136.846588 -208.808612 \nL 138.117638 -206.840701 \nL 139.450154 -204.87279 \nL 140.822556 -202.904879 \nL 142.19669 -200.936967 \nL 143.52604 -198.969056 \nL 144.771992 -197.001145 \nL 145.919754 -195.033233 \nL 146.984338 -193.065322 \nL 148.001992 -191.097411 \nL 149.010811 -189.129499 \nL 150.030882 -187.161588 \nL 151.055394 -185.193677 \nL 152.058 -183.225766 \nL 153.011652 -181.257854 \nL 153.907175 -179.289943 \nL 154.761405 -177.322032 \nL 155.612767 -175.35412 \nL 156.509285 -173.386209 \nL 157.495047 -171.418298 \nL 158.598256 -169.450387 \nL 159.822592 -167.482475 \nL 161.145323 -165.514564 \nL 162.526449 -163.546653 \nL 163.928771 -161.578741 \nL 165.339727 -159.61083 \nL 166.77985 -157.642919 \nL 168.288134 -155.675007 \nL 169.891033 -153.707096 \nL 171.576181 -151.739185 \nL 173.289452 -149.771274 \nL 174.955322 -147.803362 \nL 176.503756 -145.835451 \nL 177.887988 -143.86754 \nL 179.092329 -141.899628 \nL 180.138484 -139.931717 \nL 181.0924 -137.963806 \nL 182.061199 -135.995895 \nL 183.168427 -134.027983 \nL 184.509782 -132.060072 \nL 186.108329 -130.092161 \nL 187.893227 -128.124249 \nL 189.715222 -126.156338 \nL 191.392875 -124.188427 \nL 192.767644 -122.220516 \nL 193.742766 -120.252604 \nL 194.291866 -118.284693 \nL 194.44125 -116.316782 \nL 194.243397 -114.34887 \nL 193.759363 -112.380959 \nL 193.05465 -110.413048 \nL 192.197032 -108.445136 \nL 191.241578 -106.477225 \nL 190.203954 -104.509314 \nL 189.043704 -102.541403 \nL 187.680472 -100.573491 \nL 186.042066 -98.60558 \nL 184.115645 -96.637669 \nL 181.968901 -94.669757 \nL 179.729013 -92.701846 \nL 177.532407 -90.733935 \nL 175.469524 -88.766024 \nL 173.546104 -86.798112 \nL 171.675273 -84.830201 \nL 169.706403 -82.86229 \nL 167.484857 -80.894378 \nL 164.922115 -78.926467 \nL 162.046502 -76.958556 \nL 159.008545 -74.990644 \nL 156.031939 -73.022733 \nL 153.323663 -71.054822 \nL 150.977384 -69.086911 \nL 148.9161 -67.118999 \nL 146.913855 -65.151088 \nL 144.702971 -63.183177 \nL 142.120403 -61.215265 \nL 139.209899 -59.247354 \nL 136.21425 -57.279443 \nL 133.461806 -55.311532 \nL 131.220507 -53.34362 \nL 129.604896 -51.375709 \nL 128.572968 -49.407798 \nL 127.988034 -47.439886 \nz\n\" id=\"mcf41300185\" style=\"stroke:#3f3f3f;stroke-width:1.5;\"/>\n    </defs>\n    <g clip-path=\"url(#pb489fe4af5)\">\n     <use style=\"fill:#3274a1;stroke:#3f3f3f;stroke-width:1.5;\" x=\"0\" xlink:href=\"#mcf41300185\" y=\"263.513624\"/>\n    </g>\n   </g>\n   <g id=\"PolyCollection_2\">\n    <defs>\n     <path d=\"M 294.906219 -50.815682 \nL 294.856281 -50.815682 \nL 294.78636 -52.778277 \nL 294.598925 -54.740872 \nL 294.221639 -56.703467 \nL 293.662004 -58.666063 \nL 293.069452 -60.628658 \nL 292.644563 -62.591253 \nL 292.438317 -64.553848 \nL 292.280358 -66.516444 \nL 291.934224 -68.479039 \nL 291.28452 -70.441634 \nL 290.364014 -72.40423 \nL 289.260078 -74.366825 \nL 288.041902 -76.32942 \nL 286.762055 -78.292015 \nL 285.482906 -80.254611 \nL 284.268743 -82.217206 \nL 283.14136 -84.179801 \nL 282.04743 -86.142396 \nL 280.887214 -88.104992 \nL 279.586222 -90.067587 \nL 278.114784 -92.030182 \nL 276.438984 -93.992778 \nL 274.54969 -95.955373 \nL 272.610582 -97.917968 \nL 270.97709 -99.880563 \nL 269.926371 -101.843159 \nL 269.366642 -103.805754 \nL 268.880756 -105.768349 \nL 268.056642 -107.730944 \nL 266.75398 -109.69354 \nL 265.10545 -111.656135 \nL 263.351169 -113.61873 \nL 261.690464 -115.581326 \nL 260.238134 -117.543921 \nL 259.055821 -119.506516 \nL 258.162799 -121.469111 \nL 257.487504 -123.431707 \nL 256.854587 -125.394302 \nL 256.089011 -127.356897 \nL 255.134709 -129.319492 \nL 254.037661 -131.282088 \nL 252.846651 -133.244683 \nL 251.587585 -135.207278 \nL 250.297027 -137.169874 \nL 249.012814 -139.132469 \nL 247.755555 -141.095064 \nL 246.565692 -143.057659 \nL 245.527668 -145.020255 \nL 244.713594 -146.98285 \nL 244.119925 -148.945445 \nL 243.67999 -150.90804 \nL 243.313302 -152.870636 \nL 242.947795 -154.833231 \nL 242.522823 -156.795826 \nL 242.006555 -158.758422 \nL 241.430538 -160.721017 \nL 240.902236 -162.683612 \nL 240.558187 -164.646207 \nL 240.479982 -166.608803 \nL 240.630477 -168.571398 \nL 240.859876 -170.533993 \nL 241.000928 -172.496589 \nL 240.991043 -174.459184 \nL 240.903982 -176.421779 \nL 240.841503 -178.384374 \nL 240.779997 -180.34697 \nL 240.547093 -182.309565 \nL 239.979345 -184.27216 \nL 239.105008 -186.234755 \nL 238.177586 -188.197351 \nL 237.538715 -190.159946 \nL 237.426932 -192.122541 \nL 237.874738 -194.085137 \nL 238.73135 -196.047732 \nL 239.749684 -198.010327 \nL 240.710008 -199.972922 \nL 241.56701 -201.935518 \nL 242.498034 -203.898113 \nL 243.75261 -205.860708 \nL 245.449873 -207.823303 \nL 247.544719 -209.785899 \nL 249.932373 -211.748494 \nL 252.516556 -213.711089 \nL 255.227247 -215.673685 \nL 258.083954 -217.63628 \nL 261.264224 -219.598875 \nL 265.022947 -221.56147 \nL 269.450754 -223.524066 \nL 274.29726 -225.486661 \nL 279.072422 -227.449256 \nL 283.338317 -229.411851 \nL 286.894005 -231.374447 \nL 289.719195 -233.337042 \nL 291.837457 -235.299637 \nL 293.28362 -237.262233 \nL 294.150235 -239.224828 \nL 294.594685 -241.187423 \nL 294.786543 -243.150018 \nL 294.855282 -245.112614 \nL 294.907218 -245.112614 \nL 294.907218 -245.112614 \nL 294.975957 -243.150018 \nL 295.167815 -241.187423 \nL 295.612265 -239.224828 \nL 296.47888 -237.262233 \nL 297.925043 -235.299637 \nL 300.043305 -233.337042 \nL 302.868495 -231.374447 \nL 306.424183 -229.411851 \nL 310.690078 -227.449256 \nL 315.46524 -225.486661 \nL 320.311746 -223.524066 \nL 324.739553 -221.56147 \nL 328.498276 -219.598875 \nL 331.678546 -217.63628 \nL 334.535253 -215.673685 \nL 337.245944 -213.711089 \nL 339.830127 -211.748494 \nL 342.217781 -209.785899 \nL 344.312627 -207.823303 \nL 346.00989 -205.860708 \nL 347.264466 -203.898113 \nL 348.19549 -201.935518 \nL 349.052492 -199.972922 \nL 350.012816 -198.010327 \nL 351.03115 -196.047732 \nL 351.887762 -194.085137 \nL 352.335568 -192.122541 \nL 352.223785 -190.159946 \nL 351.584914 -188.197351 \nL 350.657492 -186.234755 \nL 349.783155 -184.27216 \nL 349.215407 -182.309565 \nL 348.982503 -180.34697 \nL 348.920997 -178.384374 \nL 348.858518 -176.421779 \nL 348.771457 -174.459184 \nL 348.761572 -172.496589 \nL 348.902624 -170.533993 \nL 349.132023 -168.571398 \nL 349.282518 -166.608803 \nL 349.204313 -164.646207 \nL 348.860264 -162.683612 \nL 348.331962 -160.721017 \nL 347.755945 -158.758422 \nL 347.239677 -156.795826 \nL 346.814705 -154.833231 \nL 346.449198 -152.870636 \nL 346.08251 -150.90804 \nL 345.642575 -148.945445 \nL 345.048906 -146.98285 \nL 344.234832 -145.020255 \nL 343.196808 -143.057659 \nL 342.006945 -141.095064 \nL 340.749686 -139.132469 \nL 339.465473 -137.169874 \nL 338.174915 -135.207278 \nL 336.915849 -133.244683 \nL 335.724839 -131.282088 \nL 334.627791 -129.319492 \nL 333.673489 -127.356897 \nL 332.907913 -125.394302 \nL 332.274996 -123.431707 \nL 331.599701 -121.469111 \nL 330.706679 -119.506516 \nL 329.524366 -117.543921 \nL 328.072036 -115.581326 \nL 326.411331 -113.61873 \nL 324.65705 -111.656135 \nL 323.00852 -109.69354 \nL 321.705858 -107.730944 \nL 320.881744 -105.768349 \nL 320.395858 -103.805754 \nL 319.836129 -101.843159 \nL 318.78541 -99.880563 \nL 317.151918 -97.917968 \nL 315.21281 -95.955373 \nL 313.323516 -93.992778 \nL 311.647716 -92.030182 \nL 310.176278 -90.067587 \nL 308.875286 -88.104992 \nL 307.71507 -86.142396 \nL 306.62114 -84.179801 \nL 305.493757 -82.217206 \nL 304.279594 -80.254611 \nL 303.000445 -78.292015 \nL 301.720598 -76.32942 \nL 300.502422 -74.366825 \nL 299.398486 -72.40423 \nL 298.47798 -70.441634 \nL 297.828276 -68.479039 \nL 297.482142 -66.516444 \nL 297.324183 -64.553848 \nL 297.117937 -62.591253 \nL 296.693048 -60.628658 \nL 296.100496 -58.666063 \nL 295.540861 -56.703467 \nL 295.163575 -54.740872 \nL 294.97614 -52.778277 \nL 294.906219 -50.815682 \nz\n\" id=\"m223be41f50\" style=\"stroke:#3f3f3f;stroke-width:1.5;\"/>\n    </defs>\n    <g clip-path=\"url(#pb489fe4af5)\">\n     <use style=\"fill:#e1812c;stroke:#3f3f3f;stroke-width:1.5;\" x=\"0\" xlink:href=\"#m223be41f50\" y=\"263.513624\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m086415fb10\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"127.48125\" xlink:href=\"#m086415fb10\" y=\"225.957374\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(124.3 240.555811)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"294.88125\" xlink:href=\"#m086415fb10\" y=\"225.957374\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1 -->\n      <g transform=\"translate(291.7 240.555811)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_3\">\n     <!-- x -->\n     <g transform=\"translate(208.221875 254.233936)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-120\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_3\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m0ddd8d4df5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0ddd8d4df5\" y=\"202.336648\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 206.135867)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0ddd8d4df5\" y=\"175.002729\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.3 -->\n      <g transform=\"translate(20.878125 178.801948)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0ddd8d4df5\" y=\"147.668811\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 151.46803)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0ddd8d4df5\" y=\"120.334893\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.5 -->\n      <g transform=\"translate(20.878125 124.134111)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0ddd8d4df5\" y=\"93.000974\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 96.800193)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0ddd8d4df5\" y=\"65.667056\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.7 -->\n      <g transform=\"translate(20.878125 69.466274)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0ddd8d4df5\" y=\"38.333137\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 42.132356)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#m0ddd8d4df5\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.9 -->\n      <g transform=\"translate(20.878125 14.798437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_12\">\n     <!-- y -->\n     <g transform=\"translate(14.798438 120.196749)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-121\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#pb489fe4af5)\" d=\"M 127.48125 204.276905 \nL 127.48125 37.885121 \n\" style=\"fill:none;stroke:#3f3f3f;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#pb489fe4af5)\" d=\"M 127.48125 163.504236 \nL 127.48125 111.467644 \n\" style=\"fill:none;stroke:#3f3f3f;stroke-linecap:square;stroke-width:4.5;\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#pb489fe4af5)\" d=\"M 294.88125 205.116507 \nL 294.88125 25.982445 \n\" style=\"fill:none;stroke:#3f3f3f;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#pb489fe4af5)\" d=\"M 294.88125 129.166707 \nL 294.88125 70.215994 \n\" style=\"fill:none;stroke:#3f3f3f;stroke-linecap:square;stroke-width:4.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 225.957374 \nL 43.78125 8.517374 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 378.58125 225.957374 \nL 378.58125 8.517374 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 225.957374 \nL 378.58125 225.957374 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 8.517374 \nL 378.58125 8.517374 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 1.5 \nC 0.397805 1.5 0.77937 1.341951 1.06066 1.06066 \nC 1.341951 0.77937 1.5 0.397805 1.5 0 \nC 1.5 -0.397805 1.341951 -0.77937 1.06066 -1.06066 \nC 0.77937 -1.341951 0.397805 -1.5 0 -1.5 \nC -0.397805 -1.5 -0.77937 -1.341951 -1.06066 -1.06066 \nC -1.341951 -0.77937 -1.5 -0.397805 -1.5 0 \nC -1.5 0.397805 -1.341951 0.77937 -1.06066 1.06066 \nC -0.77937 1.341951 -0.397805 1.5 0 1.5 \nz\n\" id=\"m44a8fed7ae\" style=\"stroke:#3f3f3f;\"/>\n    </defs>\n    <g clip-path=\"url(#pb489fe4af5)\">\n     <use style=\"fill:#ffffff;stroke:#3f3f3f;\" x=\"127.48125\" xlink:href=\"#m44a8fed7ae\" y=\"140.153481\"/>\n    </g>\n   </g>\n   <g id=\"PathCollection_2\">\n    <g clip-path=\"url(#pb489fe4af5)\">\n     <use style=\"fill:#ffffff;stroke:#3f3f3f;\" x=\"294.88125\" xlink:href=\"#m44a8fed7ae\" y=\"98.322749\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb489fe4af5\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"43.78125\" y=\"8.517374\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Plot violin plot to have an idea of the class separations\n",
    "probs_train = model.predict_proba(X_train)\n",
    "\n",
    "plot_df = pd.DataFrame({\"x\": y_train, \"y\": probs_train[:, 1]})\n",
    "sns.violinplot(data=plot_df, y=\"y\", x=\"x\")"
   ]
  },
  {
   "source": [
    "The random forest separates better both classes..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Is it perhaps better to scale the featues...it should not make much difference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plain model score:  [0.72198092 0.71266234 0.71743894 0.70876174 0.72087879]\n",
      "mean test score:  0.7163445435834437\n",
      "mean train score:  0.74880333288658\n",
      "Plain model score:  [0.72142678 0.7133679  0.71844487 0.70898827 0.72231814]\n",
      "mean test score:  0.7169091933768357\n",
      "mean train score:  0.7493335286674647\n",
      "Plain model score:  [0.71515465 0.71068011 0.71192176 0.6988689  0.71464697]\n",
      "mean test score:  0.7102544784972009\n",
      "mean train score:  0.7370420584652779\n"
     ]
    }
   ],
   "source": [
    "# K fold cross validation performace of model with no scaling\n",
    "model_1 = ensemble.RandomForestClassifier(n_estimators=100, min_samples_split=1000, max_depth=20, class_weight=\"balanced\", max_leaf_nodes=100)\n",
    "result = model_selection.cross_validate(model_1, X_train, y_train, cv=5, scoring=\"roc_auc\", return_train_score=True)\n",
    "print(\"Plain model score: \", result[\"test_score\"])\n",
    "print(\"mean test score: \", np.mean(result[\"test_score\"]))\n",
    "print(\"mean train score: \", np.mean(result[\"train_score\"]))\n",
    "\n",
    "# K fold cross validation performace of model with scaling\n",
    "model_2 = pipeline.Pipeline( [(\"scaler\", preprocessing.StandardScaler()), (\"predictor\", model_1)] )\n",
    "result = model_selection.cross_validate(model_2, X_train, y_train, cv=5, scoring=\"roc_auc\", return_train_score=True)\n",
    "print(\"Plain model score: \", result[\"test_score\"])\n",
    "print(\"mean test score: \", np.mean(result[\"test_score\"]))\n",
    "print(\"mean train score: \", np.mean(result[\"train_score\"]))\n",
    "\n",
    "\n",
    "# K fold cross validation performace of model with one hot encoding of day of week\n",
    "compose_scaler = compose.ColumnTransformer( [(\"scaler\", preprocessing.StandardScaler(), ['to_user_distance', 'to_user_elevation', 'total_earning', 'time_of_day'])],\n",
    "                                                        remainder=\"passthrough\")\n",
    "\n",
    "compose_encoder = compose.ColumnTransformer( [(\"encoder\", preprocessing.OneHotEncoder(), [4, 5])],\n",
    "                                             remainder=\"passthrough\")\n",
    "\n",
    "model_3 = pipeline.Pipeline( [  (\"scaler\", compose_scaler), \n",
    "                                (\"encoder\", compose_encoder), \n",
    "                                (\"predictor\", model_1)] )\n",
    "\n",
    "result = model_selection.cross_validate(model_3, X_train, y_train, cv=5, scoring=\"roc_auc\", return_train_score=True)\n",
    "print(\"Plain model score: \", result[\"test_score\"])\n",
    "print(\"mean test score: \", np.mean(result[\"test_score\"]))\n",
    "print(\"mean train score: \", np.mean(result[\"train_score\"]))\n"
   ]
  },
  {
   "source": [
    "Scaling does not increments performance, one hot encoding does not increase performance in this case"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Add popular store info..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we want to compute if a store is popular, in the sense that many orders are taken for that store\n",
    "# We compute the probability of taken for the store ids\n",
    "# This probability is only reliable if we have enough data for that particular store\n",
    "# We define a store to be popular if:\n",
    "#     (number_data_points(store_id) > th1) and (prob_taken(store_id) > th2\n",
    "# We define a store to be un_popular if:\n",
    "#     (number_data_points(store_id) > th1) and (prob_taken(store_id) < th3\n",
    "# If a store is not popular or unpopular the it is undefined\n",
    "\n",
    "aux = orders_df.copy()\n",
    "\n",
    "# Add columns \"is_taken\" and \"not_taken\"\n",
    "aux[\"is_taken\"] = (aux[\"taken\"] == 1) \n",
    "aux[\"not_taken\"] = (aux[\"taken\"] == 0)\n",
    "\n",
    "# Group by store_id and sum the number of taken, is_taken and not_taken\n",
    "aux = aux.groupby(\"store_id\").agg(\"sum\")[[\"taken\", \"is_taken\", \"not_taken\"]]\n",
    "\n",
    "# Total orders is just the sum of taken and not taken\n",
    "aux[\"total_orders\"] = (aux[\"is_taken\"] + aux[\"not_taken\"])\n",
    "\n",
    "# The store rating is its propability of taken\n",
    "aux[\"rating\"] = aux[\"is_taken\"] / aux[\"total_orders\"] \n",
    "aux = aux.sort_values(\"rating\", ascending=False)\n",
    "\n",
    "# Create the popularity column\n",
    "aux[\"popularity\"] = 0\n",
    "\n",
    "th1 = 50\n",
    "th2 = 0.66\n",
    "th3 = 0.33\n",
    "filter_popular = (aux[\"total_orders\"] > th1) & (aux[\"rating\"] > th2)\n",
    "filter_unpopular = (aux[\"total_orders\"] > th1) & (aux[\"rating\"] < th3)\n",
    "\n",
    "aux.loc[filter_popular, \"popularity\"] = 1\n",
    "aux.loc[filter_unpopular, \"popularity\"] = -1\n",
    "\n",
    "# Get the popular stores\n",
    "popular_store_ids = aux.loc[ aux[\"popularity\"] == 1].index\n",
    "popular_stores_ids = list(popular_store_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_popular = X_train.copy()\n",
    "X_train_popular[\"store_id\"] = orders_df.loc[X_train_popular.index, \"store_id\"]\n",
    "X_train_popular[\"popular_store\"] = X_train_popular.apply( lambda row: 1 if (row.store_id in popular_store_ids) else 0, axis=1 )\n",
    "X_train_popular.drop(columns=\"store_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plain model score:  [0.71712593 0.71396957 0.71661866 0.70173966 0.71664756]\nmean test score:  0.7132202746779301\nmean train score:  0.7396591940642575\n"
     ]
    }
   ],
   "source": [
    "# K fold cross validation performace of model with one hot encoding of day of week\n",
    "compose_scaler = compose.ColumnTransformer( [(\"scaler\", preprocessing.StandardScaler(), ['to_user_distance', 'to_user_elevation', 'total_earning', 'time_of_day'])],\n",
    "                                                        remainder=\"passthrough\")\n",
    "\n",
    "compose_encoder = compose.ColumnTransformer( [(\"encoder\", preprocessing.OneHotEncoder(), [4, 5])],\n",
    "                                             remainder=\"passthrough\")\n",
    "\n",
    "model_3 = pipeline.Pipeline( [  (\"scaler\", compose_scaler), \n",
    "                                (\"encoder\", compose_encoder), \n",
    "                                (\"predictor\", model_1)] )\n",
    "\n",
    "result = model_selection.cross_validate(model_3, X_train_popular, y_train, cv=5, scoring=\"roc_auc\", return_train_score=True)\n",
    "print(\"Plain model score: \", result[\"test_score\"])\n",
    "print(\"mean test score: \", np.mean(result[\"test_score\"]))\n",
    "print(\"mean train score: \", np.mean(result[\"train_score\"]))"
   ]
  },
  {
   "source": [
    "No change adding popular stores ids..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Fine tuning - parameter optimizations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier(n_estimators=100, min_samples_split=1000, max_depth=20, class_weight=\"balanced\", max_leaf_nodes=100)\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 200, num = 25)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 10, 100, 1000]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# ;ax leaf nodes\n",
    "max_leaf_nodes= [10, 50, 100, 200, None]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_leaf_nodes': max_leaf_nodes}\n",
    "\n",
    "random_search = model_selection.RandomizedSearchCV( model, \n",
    "                                                    param_distributions=random_grid, \n",
    "                                                    n_iter=25,\n",
    "                                                    scoring=\"roc_auc\",\n",
    "                                                    cv=5,\n",
    "                                                    refit=False,\n",
    "                                                    random_state=314,\n",
    "                                                    return_train_score=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 8.34786687,  8.27620044,  9.74055014, 10.13704538,  4.53684158,\n",
       "         5.02132301,  4.83336453,  6.60194283,  3.74895058,  3.91556158,\n",
       "         5.0776834 ,  3.30332265,  9.33463693,  8.98345408,  6.19160571,\n",
       "         5.45703812,  2.5358386 , 13.87705884, 10.26902409, 18.72459702,\n",
       "         3.24834433,  7.45132837, 10.94447546,  8.85800495, 10.05396943]),\n",
       " 'std_fit_time': array([0.11426394, 0.22871625, 0.05706231, 0.0399617 , 0.06011939,\n",
       "        0.12438112, 0.08425802, 0.12949209, 0.06886514, 0.01989041,\n",
       "        0.05318024, 0.02880925, 0.06365248, 0.12736501, 0.10448899,\n",
       "        0.06319445, 0.0441031 , 0.27761832, 0.19968596, 0.80746102,\n",
       "        0.03376782, 0.16024089, 0.10213115, 0.1483919 , 0.45660659]),\n",
       " 'mean_score_time': array([0.24139652, 0.185217  , 0.22264643, 0.24293962, 0.1114048 ,\n",
       "        0.12412434, 0.14288301, 0.14879827, 0.09318829, 0.09708061,\n",
       "        0.11670451, 0.07890515, 0.20999436, 0.20230365, 0.14749856,\n",
       "        0.13388214, 0.06785059, 0.31074862, 0.25039072, 0.65043778,\n",
       "        0.079356  , 0.16747427, 0.241713  , 0.20193419, 0.22238965]),\n",
       " 'std_score_time': array([2.38168321e-03, 1.01008951e-03, 8.42194338e-04, 1.21956815e-03,\n",
       "        3.53266140e-04, 1.32161340e-03, 1.36887621e-03, 9.48457037e-05,\n",
       "        3.91189137e-04, 3.21379840e-03, 2.44780880e-04, 9.82009416e-04,\n",
       "        8.94054252e-04, 2.48311182e-04, 6.19942750e-03, 4.68319944e-04,\n",
       "        4.26000643e-03, 4.51555080e-03, 4.09931927e-02, 4.27157588e-02,\n",
       "        2.12119671e-03, 3.04728478e-03, 1.54653055e-03, 2.17298096e-03,\n",
       "        1.28600673e-03]),\n",
       " 'param_n_estimators': masked_array(data=[87, 125, 168, 150, 68, 125, 50, 100, 56, 68, 87, 50,\n",
       "                    143, 156, 106, 137, 62, 187, 175, 168, 56, 112, 187,\n",
       "                    150, 131],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[100, 10, 1000, 100, 1000, 1000, 100, 100, 1000, 1000,\n",
       "                    100, 2, 10, 2, 1000, 100, 1000, 10, 100, 2, 100, 2,\n",
       "                    100, 1000, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[2, 4, 4, 2, 1, 2, 2, 2, 2, 1, 1, 2, 4, 2, 2, 1, 1, 2,\n",
       "                    1, 2, 4, 4, 2, 2, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_leaf_nodes': masked_array(data=[None, 100, 50, 200, 100, 10, None, 100, 100, 50, 50,\n",
       "                    100, 100, 50, 50, 10, 10, 200, 50, None, 50, 100, 50,\n",
       "                    50, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['sqrt', 'auto', 'sqrt', 'auto', 'auto', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'auto', 'sqrt', 'auto', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'sqrt', 'auto', 'sqrt', 'auto', 'sqrt', 'sqrt', 'sqrt',\n",
       "                    'auto', 'auto', 'sqrt', 'sqrt'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[50, 40, 40, 10, 40, 30, 90, None, 30, 10, 80, 90, 50,\n",
       "                    110, 60, 70, 50, 110, 80, 50, 100, 80, 40, 90, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 87,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': None,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 125,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_leaf_nodes': 100,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 168,\n",
       "   'min_samples_split': 1000,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_leaf_nodes': 50,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 150,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 200,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 68,\n",
       "   'min_samples_split': 1000,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_leaf_nodes': 100,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 125,\n",
       "   'min_samples_split': 1000,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': None,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 90},\n",
       "  {'n_estimators': 100,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 100,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': None},\n",
       "  {'n_estimators': 56,\n",
       "   'min_samples_split': 1000,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 100,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 30},\n",
       "  {'n_estimators': 68,\n",
       "   'min_samples_split': 1000,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_leaf_nodes': 50,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 10},\n",
       "  {'n_estimators': 87,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_leaf_nodes': 50,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 80},\n",
       "  {'n_estimators': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 100,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 90},\n",
       "  {'n_estimators': 143,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_leaf_nodes': 100,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 156,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 50,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 110},\n",
       "  {'n_estimators': 106,\n",
       "   'min_samples_split': 1000,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 50,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 60},\n",
       "  {'n_estimators': 137,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_leaf_nodes': 10,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 70},\n",
       "  {'n_estimators': 62,\n",
       "   'min_samples_split': 1000,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_leaf_nodes': 10,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 187,\n",
       "   'min_samples_split': 10,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 200,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 110},\n",
       "  {'n_estimators': 175,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'max_leaf_nodes': 50,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 80},\n",
       "  {'n_estimators': 168,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': None,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50},\n",
       "  {'n_estimators': 56,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_leaf_nodes': 50,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 100},\n",
       "  {'n_estimators': 112,\n",
       "   'min_samples_split': 2,\n",
       "   'min_samples_leaf': 4,\n",
       "   'max_leaf_nodes': 100,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 80},\n",
       "  {'n_estimators': 187,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 50,\n",
       "   'max_features': 'auto',\n",
       "   'max_depth': 40},\n",
       "  {'n_estimators': 150,\n",
       "   'min_samples_split': 1000,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 50,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 90},\n",
       "  {'n_estimators': 131,\n",
       "   'min_samples_split': 100,\n",
       "   'min_samples_leaf': 2,\n",
       "   'max_leaf_nodes': 200,\n",
       "   'max_features': 'sqrt',\n",
       "   'max_depth': 50}],\n",
       " 'split0_test_score': array([0.74302912, 0.72370416, 0.71151682, 0.72452398, 0.72073743,\n",
       "        0.67908236, 0.73995934, 0.72206328, 0.72201006, 0.7096516 ,\n",
       "        0.71238127, 0.72280958, 0.72232073, 0.71105678, 0.71160063,\n",
       "        0.68124278, 0.67629864, 0.73060876, 0.71212791, 0.7296767 ,\n",
       "        0.70991802, 0.72370087, 0.71277247, 0.71027534, 0.73072522]),\n",
       " 'split1_test_score': array([0.73319681, 0.71620854, 0.70471435, 0.71648144, 0.71306888,\n",
       "        0.67517614, 0.73440514, 0.71279218, 0.71136882, 0.70202055,\n",
       "        0.70177411, 0.71417223, 0.7159662 , 0.70651075, 0.70295909,\n",
       "        0.67547244, 0.67470345, 0.72383052, 0.7063926 , 0.72199096,\n",
       "        0.70287094, 0.71631637, 0.7054321 , 0.70445738, 0.72345663]),\n",
       " 'split2_test_score': array([0.73634852, 0.71919574, 0.70958819, 0.71896947, 0.72030776,\n",
       "        0.68595948, 0.73619526, 0.71863041, 0.71550597, 0.70890952,\n",
       "        0.71092393, 0.72003092, 0.71970782, 0.70881134, 0.7091414 ,\n",
       "        0.68636396, 0.68520676, 0.72522915, 0.71105723, 0.72244298,\n",
       "        0.70918821, 0.71846256, 0.71038117, 0.71066441, 0.72610223]),\n",
       " 'split3_test_score': array([0.73049232, 0.71084637, 0.69818372, 0.71054199, 0.70722241,\n",
       "        0.66701028, 0.72813122, 0.70937106, 0.7067532 , 0.69458901,\n",
       "        0.69828962, 0.70754422, 0.70839414, 0.69813725, 0.69645994,\n",
       "        0.66869781, 0.66415529, 0.71702438, 0.70043313, 0.71482592,\n",
       "        0.69784268, 0.70909183, 0.69832355, 0.6977084 , 0.71917419]),\n",
       " 'split4_test_score': array([0.73697363, 0.72351442, 0.7127255 , 0.7234776 , 0.72216279,\n",
       "        0.68276756, 0.73444667, 0.72332411, 0.72172222, 0.70943466,\n",
       "        0.71306273, 0.724574  , 0.72448565, 0.71290464, 0.71393627,\n",
       "        0.68310141, 0.68303716, 0.73103805, 0.71431469, 0.7240376 ,\n",
       "        0.71170348, 0.72487491, 0.71357868, 0.7128426 , 0.73139989]),\n",
       " 'mean_test_score': array([0.73600808, 0.71869385, 0.70734571, 0.7187989 , 0.71669985,\n",
       "        0.67799916, 0.73462752, 0.71723621, 0.71547205, 0.70492107,\n",
       "        0.70728633, 0.71782619, 0.71817491, 0.70748415, 0.70681947,\n",
       "        0.67897568, 0.67668026, 0.72554617, 0.70886511, 0.72259483,\n",
       "        0.70630467, 0.71848931, 0.7080976 , 0.70718963, 0.72617163]),\n",
       " 'std_test_score': array([0.00421118, 0.00482396, 0.00533358, 0.00506445, 0.00569506,\n",
       "        0.00657271, 0.00382545, 0.00536501, 0.00591043, 0.00589615,\n",
       "        0.00606437, 0.00623375, 0.00565517, 0.00514235, 0.00634227,\n",
       "        0.00623948, 0.00740324, 0.00512748, 0.00494693, 0.00475349,\n",
       "        0.00517521, 0.005674  , 0.0056524 , 0.00549383, 0.00456968]),\n",
       " 'rank_test_score': array([ 1,  7, 17,  6, 12, 24,  2, 11, 13, 22, 18, 10,  9, 16, 20, 23, 25,\n",
       "         4, 14,  5, 21,  8, 15, 19,  3], dtype=int32),\n",
       " 'split0_train_score': array([0.9093765 , 0.75448396, 0.72562111, 0.77707135, 0.74867339,\n",
       "        0.68225948, 0.90605346, 0.7528216 , 0.74810888, 0.72469569,\n",
       "        0.72789501, 0.75330038, 0.75388232, 0.72701259, 0.72664672,\n",
       "        0.683758  , 0.67974125, 0.78906818, 0.72688779, 0.99995597,\n",
       "        0.72656163, 0.75438052, 0.72777638, 0.7248197 , 0.78861391]),\n",
       " 'split1_train_score': array([0.90812978, 0.75640483, 0.72806057, 0.77746953, 0.74818357,\n",
       "        0.68443241, 0.90815866, 0.7530844 , 0.74782598, 0.72479076,\n",
       "        0.72598   , 0.75439117, 0.75585078, 0.73081491, 0.7258875 ,\n",
       "        0.68519118, 0.68451781, 0.79022096, 0.73012672, 0.99994016,\n",
       "        0.72743963, 0.75582009, 0.72962911, 0.72798096, 0.78949279]),\n",
       " 'split2_train_score': array([0.91057023, 0.75579389, 0.72682524, 0.77635348, 0.74937667,\n",
       "        0.68415773, 0.90754707, 0.75503134, 0.74756405, 0.72522571,\n",
       "        0.72915633, 0.75380306, 0.75542437, 0.72738942, 0.72621651,\n",
       "        0.68460555, 0.68572868, 0.79018407, 0.72910558, 0.99994011,\n",
       "        0.72766681, 0.75391878, 0.72851996, 0.72746814, 0.78907677]),\n",
       " 'split3_train_score': array([0.90899959, 0.75755281, 0.73041729, 0.77670065, 0.74909915,\n",
       "        0.68702075, 0.90750576, 0.75601612, 0.74843436, 0.72608219,\n",
       "        0.73093914, 0.7555296 , 0.7557242 , 0.73040914, 0.72864378,\n",
       "        0.68802956, 0.68319746, 0.79001716, 0.73147863, 0.99995589,\n",
       "        0.72964521, 0.75640483, 0.73038619, 0.72902192, 0.79033905]),\n",
       " 'split4_train_score': array([0.90988924, 0.75425743, 0.72566936, 0.77679347, 0.74870569,\n",
       "        0.68137676, 0.90615109, 0.75489927, 0.74734527, 0.72293505,\n",
       "        0.7269327 , 0.75473476, 0.75468322, 0.72681181, 0.72648141,\n",
       "        0.68186724, 0.68130275, 0.79003754, 0.72757397, 0.99995741,\n",
       "        0.72578611, 0.75547142, 0.7274867 , 0.72492151, 0.78895016]),\n",
       " 'mean_train_score': array([0.90939307, 0.75569858, 0.72731872, 0.7768777 , 0.7488077 ,\n",
       "        0.68384943, 0.90708321, 0.75437055, 0.74785571, 0.72474588,\n",
       "        0.72818064, 0.75435179, 0.75511298, 0.72848757, 0.72677519,\n",
       "        0.68469031, 0.68289759, 0.78990558, 0.72903454, 0.99994991,\n",
       "        0.72741988, 0.75519913, 0.72875967, 0.72684245, 0.78929454]),\n",
       " 'std_train_score': array([8.22542031e-04, 1.22460133e-03, 1.78870248e-03, 3.74435806e-04,\n",
       "        4.06610579e-04, 1.95623102e-03, 8.34211127e-04, 1.22290734e-03,\n",
       "        3.86116772e-04, 1.02952530e-03, 1.73453441e-03, 7.67076304e-04,\n",
       "        7.36765151e-04, 1.74920651e-03, 9.68974482e-04, 2.01234073e-03,\n",
       "        2.15574225e-03, 4.26172266e-04, 1.66812952e-03, 7.99886253e-06,\n",
       "        1.29763374e-03, 9.19007314e-04, 1.09966084e-03, 1.68637622e-03,\n",
       "        5.93226263e-04])}"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "random_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.73600807931959"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n_estimators': 87,\n",
       " 'min_samples_split': 100,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 50}"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plain model score:  [0.74385797 0.73675765 0.73398269 0.72987309 0.73460127]\nmean test score:  0.7358145353199232\nmean train score:  0.9090384271482851\n"
     ]
    }
   ],
   "source": [
    "# Try out best parameters\n",
    "model_1 = ensemble.RandomForestClassifier(  n_estimators=87, \n",
    "                                            min_samples_split=100, \n",
    "                                            min_samples_leaf=2,\n",
    "                                            max_depth=50, \n",
    "                                            class_weight=\"balanced\", \n",
    "                                            max_leaf_nodes=None, \n",
    "                                            max_features=\"sqrt\")\n",
    "result = model_selection.cross_validate(model_1, X_train, y_train, cv=5, scoring=\"roc_auc\", return_train_score=True)\n",
    "print(\"Plain model score: \", result[\"test_score\"])\n",
    "print(\"mean test score: \", np.mean(result[\"test_score\"]))\n",
    "print(\"mean train score: \", np.mean(result[\"train_score\"]))"
   ]
  },
  {
   "source": [
    "This model overfitts too much...lets try out the second best parameters: \n",
    "   - 'n_estimators': 131,\n",
    "   - 'min_samples_split': 100,\n",
    "   - 'min_samples_leaf': 2,\n",
    "   - 'max_leaf_nodes': 200,\n",
    "   - 'max_features': 'sqrt',\n",
    "   - 'max_depth': 50}],"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plain model score:  [0.73089652 0.72431967 0.72785914 0.71869905 0.73076807]\nmean test score:  0.7265084893207089\nmean train score:  0.7892989973731412\n"
     ]
    }
   ],
   "source": [
    "model_1 = ensemble.RandomForestClassifier(  n_estimators=131, \n",
    "                                            min_samples_split=100, \n",
    "                                            min_samples_leaf=2,\n",
    "                                            max_depth=50, \n",
    "                                            class_weight=\"balanced\", \n",
    "                                            max_leaf_nodes=200, \n",
    "                                            max_features=\"sqrt\")\n",
    "result = model_selection.cross_validate(model_1, X_train, y_train, cv=5, scoring=\"roc_auc\", return_train_score=True)\n",
    "print(\"Plain model score: \", result[\"test_score\"])\n",
    "print(\"mean test score: \", np.mean(result[\"test_score\"]))\n",
    "print(\"mean train score: \", np.mean(result[\"train_score\"]))"
   ]
  },
  {
   "source": [
    "This model overfitts less, lets keep this model.\n",
    "\n",
    "Compute the performace over the test set:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test score:  0.6660055164226004\n"
     ]
    }
   ],
   "source": [
    "# Train over entire train test and evaluate over test set\n",
    "model_1 = ensemble.RandomForestClassifier(  n_estimators=131, \n",
    "                                            min_samples_split=100, \n",
    "                                            min_samples_leaf=2,\n",
    "                                            max_depth=50, \n",
    "                                            class_weight=\"balanced\", \n",
    "                                            max_leaf_nodes=200, \n",
    "                                            max_features=\"sqrt\")\n",
    "\n",
    "model_1.fit(X_train, y_train)\n",
    "predictions = model_1.predict(X_test)\n",
    "print(\"Test score: \", metrics.roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}